# LLM-Agents EWoK Cognitive Architectures Benchmark

This project implements cognitively inspired LLM systems for assessing agentic skills using the EWOK benchmark. 

## Quick Start

```bash
# Openrouter evaluation
python main.py --backend online --model mistralai/mistral-7b-instruct --max_items 10

# Local evaluation (vLLM server)
python main.py --backend local --max_items 20

# Log probability evaluation
python main.py --backend logprob --model mistralai/Mistral-7B-Instruct-v0.3

# Memory-assisted evaluation
python main.py --backend memory --model mistralai/mistral-7b-instruct
```


## Installation

1. Clone and install dependencies:
```bash
git clone https://github.com/juverse/LLM-Agents.git
cd LLM-Agents
pip install -r requirements.txt
```

2. Set up authentication:
Set api keys as environment variables:
For openrouter: OPENROUTER_API_KEY
For gemini: GOOGLE_API_KEY

```bash
# To get access to the dataset:
huggingface-cli login
```

3. Optional: Install vLLM for local or logprob evaluation:
```bash
pip install vllm

# Start vLLM server for logprob backend:
vllm serve mistralai/Mistral-7B-Instruct-v0.3 --port 8000
```

## Usage

### Command Line Arguments

**Main evaluation arguments (main.py):**
- `--backend` - Evaluation method: `online`, `local`, `logprob`, `memory`, `gemini` (default: `online`)
- `--model` - Model identifier (default: `mistralai/mistral-7b-instruct`)
- `--max_items` - Number of items per split (default: 100)
- `--main_prompt` - Main prompt template name without .txt (default: `study`)
- `--sub_prompts` - Comma-separated sub-prompt names without .txt (default: `belief_desire_intention`)

**Analysis arguments (analysis.py):**
- `csv_files` - Path(s) to CSV file(s) to analyze (positional arguments)
- `--format` - Output format: `analyze`, `table`, `visualize`, `all` (default: `analyze`)
- `--results_dir` - Directory containing result files (default: `./results`)


### Analysis Tools

```bash
# Statistical analysis with significance testing
python analysis.py results/*.csv --format analyze

# Generate markdown summary table
python analysis.py --format table

# Create visualization plots
python analysis.py --format visualize

# Run all analysis types
python analysis.py --format all
```

## Prompt System

The modular prompt system supports:
- **Main prompts** (`prompts/main_prompt/`): Final decision templates
- **Sub-prompts** (`prompts/sub_prompts/`): Cognitive module templates
- **Dynamic composition**: Sub-prompt results feed into main prompts

## Authors & Contact

* Moritz LÃ¶nker
* Julia Lansche  
* Marc Baumholz
