  ⎿ | name                          | model                                                |   overall |
    agent-properties |   social-interactions |   social-properties |
    |:------------------------------|:-----------------------------------------------------|----------:|-----------
    --------:|----------------------:|--------------------:|
    | bdi                           | mistralai/mistral-7b-instruct                        |     0.676 |
       0.651 |                 0.78  |               0.727 |
    | study_mistral                 | mistralai/mistral-7b-instruct                        |     0.724 |
       0.675 |                 0.826 |               0.927 |
    | nemo                          | mistralai/mistral-nemo                               |     0.693 |
       0.631 |                 0.863 |               0.905 |
    | llama                         | meta-llama/llama-3.1-8b-instruct                     |     0.597 |
       0.571 |                 0.594 |               0.759 |
    | logic                         | mistralai/mistral-7b-instruct                        |     0.648 |
       0.613 |                 0.737 |               0.773 |
    | tom                           | mistralai/mistral-7b-instruct                        |     0.717 |
       0.678 |                 0.843 |               0.832 |
    | working_memory                | mistralai/mistral-7b-instruct                        |     0.725 |
       0.701 |                 0.82  |               0.781 |
    | decision_making               | mistralai/mistral-7b-instruct                        |     0.726 |
       0.688 |                 0.794 |               0.892 |
    | localquant                    | local-vllm                                           |     0.722 |
       0.679 |                 0.806 |               0.903 |
    | logprob                       | neuralmagic/Mistral-7B-Instruct-v0.3-quantized.w8a16 |     0.701 |
       0.679 |                 0.774 |               0.759 |
    | 2025-07-08T13-18-55_ewok_eval | mistralai/mistral-7b-instruct                        |     0.833 |
       0.5   |                 1     |               1     |
    | 2025-07-08T13-33-27_ewok_eval | mistralai/mistral-7b-instruct                        |     0.617 |
       0.6   |                 0.75  |               0.5   |
    | 2025-07-08T13-36-32_ewok_eval | mistralai/mistral-7b-instruct                        |     0.512 |
       0.523 |                 0.493 |               0.52  |
    | 2025-07-08T13-38-53_ewok_eval | mistralai/mistral-7b-instruct                        |     0.812 |
       0.687 |                 0.81  |               0.94  |
    | combination_all               | mistralai/mistral-7b-instruct                        |     0.754 |
       0.717 |                 0.857 |               0.884 |
    | 2025-07-08T13-46-51_ewok_eval | mistralai/mistral-7b-instruct                        |     0.582 |
       0.55  |                 0.593 |               0.603 |
    | 2025-07-08T13-46-52_ewok_eval | mistralai/mistral-7b-instruct                        |     0.502 |
       0.5   |                 0.51  |               0.497 |
    | 2025-07-08T13-50-23_ewok_eval | mistralai/mistral-7b-instruct                        |     0.482 |
       0.48  |                 0.48  |               0.487 |
    | 2025-07-08T13-51-21_ewok_eval | mistralai/mistral-7b-instruct                        |     0.778 |
       0.64  |                 0.767 |               0.927 |
    | 2025-07-08T13-56-48_ewok_eval | mistralai/mistral-7b-instruct                        |     0.592 |
       0.51  |                 0.643 |               0.623 |
    | combination_tom_dm            | mistralai/mistral-7b-instruct                        |     0.735 |
       0.696 |                 0.854 |               0.859 |
    | 2025-07-08T13-58-58_ewok_eval | mistralai/mistral-7b-instruct                        |     0.533 |
       0.523 |                 0.553 |               0.523 |
    | 2025-07-08T13-59-35_ewok_eval | mistralai/mistral-7b-instruct                        |     0.363 |
       0.357 |                 0.367 |               0.367 |
    | 2025-07-08T14-00-27_ewok_eval | mistralai/mistral-7b-instruct                        |     0.799 |
       0.68  |                 0.8   |               0.917 |
    | 2025-07-08T14-04-40_ewok_eval | mistralai/mistral-7b-instruct                        |     0.543 |
       0.487 |                 0.56  |               0.583 |
    | 2025-07-08T14-05-17_ewok_eval | mistralai/mistral-7b-instruct                        |     0.314 |
       0.307 |                 0.24  |               0.397 |
    | 2025-07-08T14-05-44_ewok_eval | mistralai/mistral-7b-instruct                        |     0.806 |
       0.7   |                 0.79  |               0.927 |
    | 2025-07-08T14-58-11_ewok_eval | mistralai/mistral-7b-instruct                        |     0.781 |
       0.623 |                 0.787 |               0.933 |
    | 2025-07-08T15-00-32_ewok_eval | mistralai/mistral-7b-instruct                        |     0.481 |
       0.49  |                 0.497 |               0.457 |
    | combination_dm_wm             | mistralai/mistral-7b-instruct                        |     0.753 |
       0.716 |                 0.86  |               0.876 |
    | combination_tom_wm            | mistralai/mistral-7b-instruct                        |     0.748 |
       0.709 |                 0.877 |               0.865 |
    | deepseek                      | deepseek/deepseek-chat-v3-0324                       |     0.85  |
       0.803 |                 0.994 |               1     |
    | memory                        | mistralai/mistral-7b-instruct                        |     0.772 |
       0.733 |                 0.894 |               0.895 |
    | cot_2                         | mistralai/mistral-7b-instruct                        |     0.664 |
       0.602 |                 0.834 |               0.876 |
    | gemini                        | gemini-2.5-flash                                     |     0.904 |
       0.881 |                 1     |               0.957 |




# LLM-Agents EWoK Cognitive Architectures Benchmark

This project implements cognitively inspired LLM systems for assessing agentic skills using the EWOK benchmark. 

## Quick Start

```bash
# Openrouter evaluation
python main.py --backend online --model mistralai/mistral-7b-instruct --max_items 10

# Local evaluation (vLLM server)
python main.py --backend local --max_items 20

# Log probability evaluation
python main.py --backend logprob --model mistralai/Mistral-7B-Instruct-v0.3

# Memory-assisted evaluation
python main.py --backend memory --model mistralai/mistral-7b-instruct
```


## Installation

1. Clone and install dependencies:
```bash
git clone https://github.com/juverse/LLM-Agents.git
cd LLM-Agents
pip install -r requirements.txt
```

2. Set up authentication:
Set api keys as environment variables:
For openrouter: OPENROUTER_API_KEY
For gemini: GOOGLE_API_KEY

```bash
# To get access to the dataset:
huggingface-cli login
```

3. Optional: Install vLLM for local or logprob evaluation:
```bash
pip install vllm

# Start vLLM server for logprob backend:
vllm serve mistralai/Mistral-7B-Instruct-v0.3 --port 8000
```

## Usage

### Command Line Arguments

**Main evaluation arguments (main.py):**
- `--backend` - Evaluation method: `online`, `local`, `logprob`, `memory`, `gemini` (default: `online`)
- `--model` - Model identifier (default: `mistralai/mistral-7b-instruct`)
- `--max_items` - Number of items per split (default: 100)
- `--main_prompt` - Main prompt template name without .txt (default: `study`)
- `--sub_prompts` - Comma-separated sub-prompt names without .txt (default: `belief_desire_intention`)

**Analysis arguments (analysis.py):**
- `csv_files` - Path(s) to CSV file(s) to analyze (positional arguments)
- `--format` - Output format: `analyze`, `table`, `visualize`, `all` (default: `analyze`)
- `--results_dir` - Directory containing result files (default: `./results`)


### Analysis Tools

```bash
# Statistical analysis with significance testing
python analysis.py results/*.csv --format analyze

# Generate markdown summary table
python analysis.py --format table

# Create visualization plots
python analysis.py --format visualize

# Run all analysis types
python analysis.py --format all
```

## Prompt System

The modular prompt system supports:
- **Main prompts** (`prompts/main_prompt/`): Final decision templates
- **Sub-prompts** (`prompts/sub_prompts/`): Cognitive module templates
- **Dynamic composition**: Sub-prompt results feed into main prompts

## Authors & Contact

* Moritz Lönker
* Julia Lansche  
* Marc Baumholz
